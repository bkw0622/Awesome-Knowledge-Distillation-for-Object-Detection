# Knowledge-Distillation-for-Object-Detection

### [(CVPR2017) Mimicking very efficient network for object detection](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8100259)

### [(CVPR2019) Distilling object detectors with fine-grained feature imitation](https://arxiv.org/abs/1906.03609)

### [(CVPR2021) General instance distillation for object detection](https://arxiv.org/abs/2103.02340)

### [(CVPR2021) Distilling object detectors via decoupled features](https://arxiv.org/abs/2103.14475)

### [(NeurIPS2021) Distilling object detectors with feature richness](https://arxiv.org/abs/2111.00674)

### [(CVPR2022) Focal and global knowledge distillation for detectors](https://arxiv.org/abs/2111.11837)

### [(AAAI2022) Rank Mimicking and Prediction-guided Feature Imitation](https://ojs.aaai.org/index.php/AAAI/article/download/20018/version/18315/19777)

### [(ECCV2022) Prediction-Guided Distillation](https://arxiv.org/abs/2203.05469)

### [(ICLR2023 accepted) Masked Distillation with Receptive Tokens](https://arxiv.org/abs/2205.14589)


![map](https://user-images.githubusercontent.com/66883050/216757389-57061776-ac90-4545-8c97-42bcdfaa4d5e.PNG)
